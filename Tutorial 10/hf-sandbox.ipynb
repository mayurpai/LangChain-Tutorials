{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(task=\"sentiment-analysis\")(\"Love this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(task=\"sentiment-analysis\",\n",
    "         model=\"distilbert-base-uncased-finetuned-sst-2-english\")(\"Love this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                      model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"Hate this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\"This is great\",\n",
    "             \"Thanks for nothing\",\n",
    "             \"You've got to work on your face\",\n",
    "             \"You're beautiful, never change!\"]\n",
    "\n",
    "classifier(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"text-classification\",\n",
    "                      model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(text_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Hugging Face is an AI company that has become a major hub for open-source machine learning. \n",
    "Their platform has 3 major elements which allow users to access and share machine learning resources. \n",
    "First, is their rapidly growing repository of pre-trained open-source machine learning models for things such as natural language processing (NLP), computer vision, and more. \n",
    "Second, is their library of datasets for training machine learning models for almost any task. \n",
    "Third, and finally, is Spaces which is a collection of open-source ML apps.\n",
    "\n",
    "The power of these resources is that they are community generated, which leverages all the benefits of open source i.e. cost-free, wide diversity of tools, high quality resources, and rapid pace of innovation. \n",
    "While these make building powerful ML projects more accessible than before, there is another key element of the Hugging Face ecosystemâ€”their Transformers library.\n",
    "\"\"\"\n",
    "summarized_text = summarizer(text, min_length=5, max_length=140)\n",
    "summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = chatbot(\"Hi I'm Shaw, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = chatbot(\"Where do you work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_text_classes(message, history):\n",
    "    return str(classifier(message)[0][:3]).replace('}, {', '\\n').replace('[{', '').replace('}]', '')\n",
    "\n",
    "\n",
    "demo_sentiment = gr.ChatInterface(top3_text_classes, title=\"Text Sentiment Chatbot\",\n",
    "                                  description=\"Enter your text, and the chatbot will classify the sentiment.\")\n",
    "\n",
    "demo_sentiment.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer_bot(message, history):\n",
    "    return summarizer(message, min_length=5, max_length=140)[0]['summary_text']\n",
    "\n",
    "\n",
    "demo_summarizer = gr.ChatInterface(summarizer_bot, title=\"Summarizer Chatbot\",\n",
    "                                   description=\"Enter your text, and the chatbot will return the summarized version.\")\n",
    "\n",
    "demo_summarizer.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_list = []\n",
    "response_list = []\n",
    "\n",
    "\n",
    "def vanilla_chatbot(message, history):\n",
    "    conversation = chatbot(message)\n",
    "\n",
    "    return conversation[0]['generated_text']\n",
    "\n",
    "\n",
    "demo_chatbot = gr.ChatInterface(\n",
    "    vanilla_chatbot, title=\"Vanilla Chatbot\", description=\"Enter text to start chatting.\")\n",
    "\n",
    "demo_chatbot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\gradio\\routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 408, in _submit_fn\n",
      "    response = self.fn(message, history, *args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mbantwal\\AppData\\Local\\Temp\\ipykernel_1788\\3064732607.py\", line 8, in vanilla_chatbot\n",
      "    conversation = chatbot(conversation)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 165, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 1122, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 1128, in run_single\n",
      "    model_inputs = self.preprocess(inputs, **preprocess_params)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 175, in preprocess\n",
      "    inputs = self._parse_and_tokenize(inputs, truncation=truncation, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mbantwal\\Git Repositories\\Personal\\LangChain Tutorials\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 127, in _parse_and_tokenize\n",
      "    raise ValueError(\n",
      "ValueError:  `args[0]`: Conversation id: cbb8b71d-346e-4fdd-a411-6842bac2ead1 \n",
      "user >> Hi \n",
      " have the wrong format. The should be either of type `str` or type `list`\n"
     ]
    }
   ],
   "source": [
    "message_list = []\n",
    "response_list = []\n",
    "\n",
    "\n",
    "def vanilla_chatbot(message, history):\n",
    "    conversation = Conversation(\n",
    "        text=message, past_user_inputs=message_list, generated_responses=response_list)\n",
    "    conversation = chatbot(conversation)\n",
    "\n",
    "    return conversation.generated_responses[-1]\n",
    "\n",
    "\n",
    "demo_chatbot = gr.ChatInterface(\n",
    "    vanilla_chatbot, title=\"Vanilla Chatbot\", description=\"Enter text to start chatting.\")\n",
    "\n",
    "demo_chatbot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
